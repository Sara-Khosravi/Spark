{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sara Khosravi\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set environment\n",
    "import os\n",
    "import sys\n",
    " \n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Sparksession driver\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Classification of Shuttle\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+---------+--------+----+------+---------+--------+-----+\n",
      "|_c0|being time|Rad Flow|Fpv Close|Fpv Open|High|Bypass|Bpv Close|Bpv Open|class|\n",
      "+---+----------+--------+---------+--------+----+------+---------+--------+-----+\n",
      "| 49|        -3|      79|        0|      50|   0|    30|       30|       0|    1|\n",
      "| 40|        -5|      76|        1|      38|   0|    36|       37|       2|    1|\n",
      "| 49|         0|      83|        8|      50|   3|    34|       33|       0|    1|\n",
      "| 55|         0|      98|        0|      50|  -9|    42|       49|       6|    4|\n",
      "| 56|         4|      77|        0|      16|  -3|    22|       62|      40|    4|\n",
      "| 42|        -1|     108|        0|      42|   0|    65|       66|       2|    1|\n",
      "| 42|         0|      87|        8|      42|   0|    45|       46|       2|    1|\n",
      "| 57|        -2|      80|        0|      56|   0|    23|       23|       0|    1|\n",
      "| 45|        -1|     108|        0|      44|   0|    63|       64|       2|    1|\n",
      "| 46|        -3|      90|        0|      46|   6|    44|       44|       0|    1|\n",
      "| 37|         0|      76|        0|      30|  -3|    39|       45|       6|    1|\n",
      "| 48|         0|      87|       -2|      46|  -3|    39|       41|       2|    1|\n",
      "| 41|         0|      81|        0|      38| -27|    40|       43|       2|    1|\n",
      "| 41|        -1|      83|        0|      42|  11|    42|       41|       0|    1|\n",
      "| 37|         0|      80|       -1|      38|  15|    43|       41|       0|    1|\n",
      "| 41|         0|      77|       -1|      38| -30|    36|       38|       2|    1|\n",
      "| 56|         4|      86|        0|      56|  18|    31|       30|       0|    1|\n",
      "| 44|         3|      83|        0|      44|  22|    40|       39|       0|    1|\n",
      "| 47|         0|      84|        1|      46|   0|    36|       37|       0|    1|\n",
      "| 56|         0|      96|       -1|      50|  -5|    40|       47|       6|    4|\n",
      "+---+----------+--------+---------+--------+----+------+---------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('data/Shuttle.csv',inferSchema=True, header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns\n",
    "#df = df.toDF('Temperature', 'Luminosity', 'Radius', 'Absolute magnitud', 'Star type', 'Star color', 'Spectral Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+---------+--------+----+------+---------+--------+-----+\n",
      "|_c0|being time|Rad Flow|Fpv Close|Fpv Open|High|Bypass|Bpv Close|Bpv Open|class|\n",
      "+---+----------+--------+---------+--------+----+------+---------+--------+-----+\n",
      "| 49|        -3|      79|        0|      50|   0|    30|       30|       0|    1|\n",
      "| 40|        -5|      76|        1|      38|   0|    36|       37|       2|    1|\n",
      "| 49|         0|      83|        8|      50|   3|    34|       33|       0|    1|\n",
      "| 55|         0|      98|        0|      50|  -9|    42|       49|       6|    4|\n",
      "| 56|         4|      77|        0|      16|  -3|    22|       62|      40|    4|\n",
      "+---+----------+--------+---------+--------+----+------+---------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of cells in column _c0 with null values: 0\n",
      "no. of cells in column being time with null values: 0\n",
      "no. of cells in column Rad Flow with null values: 0\n",
      "no. of cells in column Fpv Close with null values: 0\n",
      "no. of cells in column Fpv Open with null values: 0\n",
      "no. of cells in column High with null values: 0\n",
      "no. of cells in column Bypass with null values: 0\n",
      "no. of cells in column Bpv Close with null values: 0\n",
      "no. of cells in column Bpv Open with null values: 0\n",
      "no. of cells in column class with null values: 0\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "for col in df.columns:\n",
    "    print(\"no. of cells in column\", col, \"with null values:\", df.filter(df[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|class|\n",
      "+--------------------+-----+\n",
      "|[-3.0,79.0,0.0,50...|    1|\n",
      "|[-5.0,76.0,1.0,38...|    1|\n",
      "|[0.0,83.0,8.0,50....|    1|\n",
      "|[0.0,98.0,0.0,50....|    4|\n",
      "|[4.0,77.0,0.0,16....|    4|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all the independent variables need to be packed into one column of vector type\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['being time','Rad Flow', 'Fpv Close', 'Fpv Open','High','Bypass','Bpv Close','Bpv Open'], \n",
    "                            outputCol=\"features\")\n",
    "feature_vec=assembler.transform(df).select('features','class')\n",
    "feature_vec.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|    1|11386|\n",
      "|    6|    4|\n",
      "|    3|   39|\n",
      "|    5|  806|\n",
      "|    4| 2135|\n",
      "|    7|    2|\n",
      "|    2|   13|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count of target classes\n",
    "feature_vec.groupBy('class').count().show()\n",
    "#there is not data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = feature_vec.randomSplit([.75,.25],seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"class\", featuresCol=\"features\",  \n",
    "                        maxIter=100, regParam=0.0001, family=\"multinomial\",  \n",
    "                        elasticNetParam=0.0)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(train_data)\n",
    "predictions = lrModel.transform(test_data)\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|class|prediction|\n",
      "+-----+----------+\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "|    1|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('class','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604743083003953"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='class', metricName='accuracy')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579412601597141"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='class', metricName='f1')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|class|count|\n",
      "+-----+-----+\n",
      "|    1| 2830|\n",
      "|    6|    2|\n",
      "|    3|    8|\n",
      "|    5|  197|\n",
      "|    4|  501|\n",
      "|    7|    1|\n",
      "|    2|    3|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('class').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#Grid Search\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "rf = RandomForestClassifier( labelCol='class',seed=0)\n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "             .addGrid(rf.maxDepth,[10,11,12])\\\n",
    "             .addGrid(rf.numTrees,[20,30,40])\\\n",
    "             .build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='class', metricName='f1')\n",
    "# Create 4-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=4)\n",
    "\n",
    "cvModel = cv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9977159836617104,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.9979056314084556,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 30}),\n",
       " (0.997941087797557,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.9977159836617104,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 11,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.9979056314084556,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 11,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 30}),\n",
       " (0.9978778126728669,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 11,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.9978469770596613,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 12,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.9981191980452542,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 12,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 30}),\n",
       " (0.9978892685534444,\n",
       "  {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 12,\n",
       "   Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 40})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cvModel.avgMetrics, cvModel.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9981191980452542,\n",
       " {Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 12,\n",
       "  Param(parent='RandomForestClassifier_4bd0bc841d07ab9c3ab9', name='numTrees', doc='Number of trees to train (>= 1).'): 30})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Model Params\n",
    "score_params_list = list(zip(cvModel.avgMetrics, cvModel.getEstimatorParamMaps()))\n",
    "max(score_params_list,key=lambda item:item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvModel.bestModel.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957334656774008"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BY implementiong Random Forest Model, we got 99% accuracy.\n",
    "#BY implementing LOGESTIC Regression Model, 96% accuracy  is gotten."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
