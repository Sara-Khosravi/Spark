{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sara Khosravi\n",
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set environment\n",
    "import os\n",
    "import sys\n",
    " \n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Sparksession driver\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Classification of Star Type\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------------------+-------------------+------------------+---------+----------+--------------+\n",
      "|_c0|temperature|          luminosity|             radius|absolute_magnitude|star_type|star_color|spectral_class|\n",
      "+---+-----------+--------------------+-------------------+------------------+---------+----------+--------------+\n",
      "|  0|       3068|              0.0024|               0.17|             16.12|        0|        10|             5|\n",
      "|  1|       3042|              5.0E-4|             0.1542|              16.6|        0|        10|             5|\n",
      "|  2|       2600|              3.0E-4|              0.102|              18.7|        0|        10|             5|\n",
      "|  3|       2800|              2.0E-4|               0.16|             16.65|        0|        10|             5|\n",
      "|  4|       1939|             1.38E-4|0.10300000000000001|             20.06|        0|        10|             5|\n",
      "|  5|       2840|              6.5E-4|               0.11|             16.98|        0|        10|             5|\n",
      "|  6|       2637|              7.3E-4|              0.127|             17.22|        0|        10|             5|\n",
      "|  7|       2600|              4.0E-4|              0.096|              17.4|        0|        10|             5|\n",
      "|  8|       2650|6.900000000000001E-4|               0.11|             17.45|        0|        10|             5|\n",
      "|  9|       2700|              1.8E-4|               0.13|             16.05|        0|        10|             5|\n",
      "| 10|       3600|              0.0029|               0.51|             10.69|        1|        10|             5|\n",
      "| 11|       3129|              0.0122|             0.3761|             11.79|        1|        10|             5|\n",
      "| 12|       3134|              4.0E-4|              0.196|             13.21|        1|        10|             5|\n",
      "| 13|       3628|              0.0055|0.39299999999999996|             10.48|        1|        10|             5|\n",
      "| 14|       2650|              6.0E-4|               0.14|            11.782|        1|        10|             5|\n",
      "| 15|       3340|              0.0038|               0.24|             13.07|        1|        10|             5|\n",
      "| 16|       2799|              0.0018|               0.16|             14.79|        1|        10|             5|\n",
      "| 17|       3692|             0.00367|               0.47|              10.8|        1|        10|             5|\n",
      "| 18|       3192|0.003620000000000...|             0.1967|             13.53|        1|        10|             5|\n",
      "| 19|       3441|               0.039|0.35100000000000003|             11.18|        1|        10|             5|\n",
      "+---+-----------+--------------------+-------------------+------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('data/StarType.csv',inferSchema=True, header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns\n",
    "#df = df.toDF('Temperature', 'Luminosity', 'Radius', 'Absolute magnitud', 'Star type', 'Star color', 'Spectral Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-------------------+------------------+---------+----------+--------------+\n",
      "|_c0|temperature|luminosity|             radius|absolute_magnitude|star_type|star_color|spectral_class|\n",
      "+---+-----------+----------+-------------------+------------------+---------+----------+--------------+\n",
      "|  0|       3068|    0.0024|               0.17|             16.12|        0|        10|             5|\n",
      "|  1|       3042|    5.0E-4|             0.1542|              16.6|        0|        10|             5|\n",
      "|  2|       2600|    3.0E-4|              0.102|              18.7|        0|        10|             5|\n",
      "|  3|       2800|    2.0E-4|               0.16|             16.65|        0|        10|             5|\n",
      "|  4|       1939|   1.38E-4|0.10300000000000001|             20.06|        0|        10|             5|\n",
      "+---+-----------+----------+-------------------+------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of cells in column _c0 with null values: 0\n",
      "no. of cells in column temperature with null values: 0\n",
      "no. of cells in column luminosity with null values: 0\n",
      "no. of cells in column radius with null values: 0\n",
      "no. of cells in column absolute_magnitude with null values: 0\n",
      "no. of cells in column star_type with null values: 0\n",
      "no. of cells in column star_color with null values: 0\n",
      "no. of cells in column spectral_class with null values: 0\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "for col in df.columns:\n",
    "    print(\"no. of cells in column\", col, \"with null values:\", df.filter(df[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|star_type|\n",
      "+--------------------+---------+\n",
      "|[3068.0,0.0024,0....|        0|\n",
      "|[3042.0,5.0E-4,0....|        0|\n",
      "|[2600.0,3.0E-4,0....|        0|\n",
      "|[2800.0,2.0E-4,0....|        0|\n",
      "|[1939.0,1.38E-4,0...|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all the independent variables need to be packed into one column of vector type\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['temperature','luminosity','radius','absolute_magnitude','star_color','spectral_class'], \n",
    "                            outputCol=\"features\")\n",
    "feature_vec=assembler.transform(df).select('features','star_type')\n",
    "feature_vec.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|star_type|count|\n",
      "+---------+-----+\n",
      "|        1|   40|\n",
      "|        3|   40|\n",
      "|        5|   40|\n",
      "|        4|   40|\n",
      "|        2|   40|\n",
      "|        0|   40|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count of target classes\n",
    "feature_vec.groupBy('star_type').count().show()\n",
    "#there is not data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = feature_vec.randomSplit([.75,.25],seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- star_type: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"star_type\", featuresCol=\"features\",  \n",
    "                        maxIter=100, regParam=0.0001, family=\"multinomial\",  \n",
    "                        elasticNetParam=0.0)\n",
    "\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(train_data)\n",
    "predictions = lrModel.transform(test_data)\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|star_type|prediction|\n",
      "+---------+----------+\n",
      "|        0|       0.0|\n",
      "|        1|       1.0|\n",
      "|        1|       1.0|\n",
      "|        0|       0.0|\n",
      "|        0|       0.0|\n",
      "|        0|       0.0|\n",
      "|        0|       0.0|\n",
      "|        0|       0.0|\n",
      "|        1|       1.0|\n",
      "|        1|       1.0|\n",
      "|        1|       1.0|\n",
      "|        0|       0.0|\n",
      "|        0|       0.0|\n",
      "|        4|       4.0|\n",
      "|        0|       0.0|\n",
      "|        1|       1.0|\n",
      "|        5|       5.0|\n",
      "|        0|       0.0|\n",
      "|        5|       5.0|\n",
      "|        5|       5.0|\n",
      "+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('star_type','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='star_type', metricName='accuracy')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='star_type', metricName='f1')\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|star_type|count|\n",
      "+---------+-----+\n",
      "|        1|    6|\n",
      "|        3|    3|\n",
      "|        5|   12|\n",
      "|        4|    7|\n",
      "|        2|   14|\n",
      "|        0|   10|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('star_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#Grid Search\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "rf = RandomForestClassifier( labelCol='star_type',seed=0)\n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "             .addGrid(rf.maxDepth,[10,11,12])\\\n",
    "             .addGrid(rf.numTrees,[20,30,40])\\\n",
    "             .build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='star_type', metricName='f1')\n",
    "# Create 4-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=4)\n",
    "\n",
    "cvModel = cv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 30}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 11,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 11,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 30}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 11,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 40}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 12,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 12,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 30}),\n",
       " (0.9761535708787319,\n",
       "  {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 12,\n",
       "   Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 40})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cvModel.avgMetrics, cvModel.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9761535708787319,\n",
       " {Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       "  Param(parent='RandomForestClassifier_4ec886f4fbb6325606f3', name='numTrees', doc='Number of trees to train (>= 1).'): 20})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Model Params\n",
    "score_params_list = list(zip(cvModel.avgMetrics, cvModel.getEstimatorParamMaps()))\n",
    "max(score_params_list,key=lambda item:item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvModel.bestModel.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9615384615384615"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY implementiong Random Forest Model, we got 96% accuracy.\n",
    "#BY implementing LOGESTIC Regression Model, 100% accuracy  is gotten."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
